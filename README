The main experiments were run on a private data set. To allow replicability, we performed additional experiments on a public data set found at http://www.statmt.org/wmt17/translation-task.html


Before executing any experiments, we must download and extract German News Crawl articles into data/raw/ by executing data/raw/downloadData.sh from within that directory. Then we must create permutations of the corpora by running src/preprocess/preshuffle.sh to be able to run the experiments testing the robustness of the WEAT towards permutation and subsampling.

Experiments can be found in src/experiments/. Any experiments should be started with working directory set to the root directory of this project. 

Folder structure:
data
-raw (raw data should be downloaded here)
-processed (scripts place preprocessed data here)
-external (any external data used for tests)
--iats (word lists )
---de (German WEAT)
---en (English WEAT used by Caliskan et al.)
---parallel (Tests for parallel comparison of psychological experiments and results computed on Calsikan et al.'s and our models)

src (contains source code)
-train (code to train word embedding models)
--word2vec
--glove
-test (semantic/syntactic and bias tests)
--GermanWordEmbeddings (code from https://github.com/devmount/GermanWordEmbeddings, we only use the syntactic/semantic tests)
-experiments 

models (scripts save models in the respective subfolders)
-glove
-word2vec

results (results of experiments are placed here)
-word2vec
-glove

paper (contains scripts and data to create the plots used in the paper)
-data
-plots
